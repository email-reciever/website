---
layout: ../../layouts/BlogLayout.astro
title: A common sense take on LLMs
description: A common sense take on LLMs
date: æ˜ŸæœŸä¸‰ 12 ä¸­åˆ ä¸‰æœˆ 26o 2025
author: alexkondov
origin_url: https://mailchi.mp/67b8e9b9b437/a-common-sense-take-on-llms?e=6955ce1080
origin_site: https://mailchi.mp/67b8e9b9b437/a-common-sense-take-on-llms?e=6955ce1080
translated: true
avatar: /media-source/alexkondov-ico.png
email_recorder: alexkondov38@147790190.mailchimpapp.com
---

import { Detail } from '@/components/Detail.tsx';
import { Reference } from '@/components/Reference.tsx';

<Reference client:only="react" title="A common sense take on LLMs" url="https://mailchi.mp/67b8e9b9b437/a-common-sense-take-on-llms?e=6955ce1080" />

<Detail client:only="react">
	![](https://mcusercontent.com/fca75767fa83fa3473478b4ca/images/38ca00ab-a0f7-cb3d-ecc8-8766da856ac2.png)

# **A Realistic Take on LLMs**

Hey all, I know you havenâ€™t subscribed to this newsletter so you can read about AI but I wanted to give a level-headed explanations about how our industry is changing thatâ€™s not driven by hype, fear or marketing budgets.

Iâ€™ve been building products and AI agents in the last month or so and hereâ€™s what Iâ€™ll be writing about today:

Here's what I've prepared:

1.  Why itâ€™s important to focus on patterns
2.  Why software design is so important right now
3.  Reflections on working on a vibe coded codebase

Letâ€™s go.

##   
Focus on patterns

I wouldnâ€™t focus on MCP, RAGs or AI agents right now. I just donâ€™t think they are that important as patterns and I expect them to evolve in the next few years. Theyâ€™re all specific implementations of abstract solutions that weâ€™ve been working on as an industry for a long time.

RAGs are essentially a data pipeline that has some level of non-determinism because of the LLM calls. AI agents are distributed workflows that again have the non-deterministic element to them. Weâ€™ve been building similar things in the past but instead of relying on strict conditional logic, we now use LLMs to draw intent our of natural language. The novel bit is a small part of the whole implementation.

If youâ€™ve ever designed a data ingestion pipeline before, you wonâ€™t have any trouble designing one now. If you havenâ€™t, youâ€™d get more valuable information researching best practices around data pipelines instead of focusing on RAGs specifically.Â 

If you have to build an AI agent or work on a RAG implementation, donâ€™t focus on the calls you make to the models. Think about how you can build a composable pipeline that you can modify and extend. Think about how you can get updates from the pipeline at every stage and get a level of transparency into whatâ€™s happening.Â 

**Always think about the high-level problem**; donâ€™t get AI tunnel vision.  
Â 

## The importance of software design

The same rules that have helped us build maintainable software help LLMs make sense of our codebases. You will notice better suggestions in a codebase where related logic is colocated, static types are used, abstractions wrap complex logic, and descriptive comments are present.

*   Co-location makes your codebase modular. It means you can understand isolated parts of the codebase without relying on external context. This means that the LLM will be able to give you better suggestions because it will be examining a smaller part of the codebase at a time.
*   Static types are a way to document your data structures and functions inside the codebase. In the same wayÂ they help you avoid runtime errors, LLMs will hallucinate less if they can refer to a type or an interface when theyâ€™re making suggestions.
*   By creating abstractions, we can reason about complex code by calling a single function, for example. By giving LLMs primitives and building blocks, we give them a more powerful way to express the logic we need. If we go back to the pipeline example again, we can define a primitive for a stage of the pipeline and have the LLM build the different steps using our building blocks.

Thereâ€™s no substitute for good software design. Code is not yet abstracted away.

LLMs can become so good in the future that code becomes an implementation detail that we almost never look at, but weâ€™re not there yet.  
Â 

## Reflections on working on a vibe-coded project

I helped a friend solve some obscure edge cases in what you would call a vibe-coded codebase. It was a project created mostly with AI with the aim of solving a specific business problem. The directions that were given to the AI were focused on product features instead of code-level details.

The result was very good. It was a great-functioning proof of concept.

But it wasnâ€™t built with extensibility in mind. So when the team wanted to take it beyond the prototype level, they started experiencing problems. The LLM was no longer capable of adding new functionality without breaking something else and sometimes its changes werenâ€™t working at all. The AI was only given instructions about what to build, not how to structure the code, and how to make sure that certain parts can be changed without affecting others.

I made an experiment and decided to attempt to fix the problems entirely with Cursor without writing the code myself.

ğŸ”´ Describing the bug the users are facing **didnâ€™t work**. It rarely gave good suggestions at all.  
ğŸŸ¡ Describing the bug in a technical way **gave better results**. However it often started refactoring whole files while there was a simpler solution available. It needed more guidance.  
ğŸŸ¢ Telling it what technical change you want to make **gave the best result**. I basically designed the solution in my head, described it to the LLM and it implemented it, taking care of edge cases.

Typing the code becomes a solved problem with every passing day, designing solutions however, is still hard. This is the difference between creating a data pipeline in a single file and having an extensible solution that you can use an LLM to enrich and extend.  
  
_Well, that's about it. Let's go create something!_

  
  
  
  
  
  


</Detail>

![](https://mcusercontent.com/fca75767fa83fa3473478b4ca/images/38ca00ab-a0f7-cb3d-ecc8-8766da856ac2.png)

# **A Realistic Take on LLMs**

Hey all, I know you havenâ€™t subscribed to this newsletter so you can read about AI but I wanted to give a level-headed explanations about how our industry is changing thatâ€™s not driven by hype, fear or marketing budgets.

Iâ€™ve been building products and AI agents in the last month or so and hereâ€™s what Iâ€™ll be writing about today:

Here's what I've prepared:

1. Why itâ€™s important to focus on patterns
2. Why software design is so important right now
3. Reflections on working on a vibe coded codebase

Letâ€™s go.

##

Focus on patterns

I wouldnâ€™t focus on MCP, RAGs or AI agents right now. I just donâ€™t think they are that important as patterns and I expect them to evolve in the next few years. Theyâ€™re all specific implementations of abstract solutions that weâ€™ve been working on as an industry for a long time.

RAGs are essentially a data pipeline that has some level of non-determinism because of the LLM calls. AI agents are distributed workflows that again have the non-deterministic element to them. Weâ€™ve been building similar things in the past but instead of relying on strict conditional logic, we now use LLMs to draw intent our of natural language. The novel bit is a small part of the whole implementation.

If youâ€™ve ever designed a data ingestion pipeline before, you wonâ€™t have any trouble designing one now. If you havenâ€™t, youâ€™d get more valuable information researching best practices around data pipelines instead of focusing on RAGs specifically.Â 

If you have to build an AI agent or work on a RAG implementation, donâ€™t focus on the calls you make to the models. Think about how you can build a composable pipeline that you can modify and extend. Think about how you can get updates from the pipeline at every stage and get a level of transparency into whatâ€™s happening.Â 

**Always think about the high-level problem**; donâ€™t get AI tunnel vision.\
Â 

## The importance of software design

The same rules that have helped us build maintainable software help LLMs make sense of our codebases. You will notice better suggestions in a codebase where related logic is colocated, static types are used, abstractions wrap complex logic, and descriptive comments are present.

* Co-location makes your codebase modular. It means you can understand isolated parts of the codebase without relying on external context. This means that the LLM will be able to give you better suggestions because it will be examining a smaller part of the codebase at a time.
* Static types are a way to document your data structures and functions inside the codebase. In the same wayÂ they help you avoid runtime errors, LLMs will hallucinate less if they can refer to a type or an interface when theyâ€™re making suggestions.
* By creating abstractions, we can reason about complex code by calling a single function, for example. By giving LLMs primitives and building blocks, we give them a more powerful way to express the logic we need. If we go back to the pipeline example again, we can define a primitive for a stage of the pipeline and have the LLM build the different steps using our building blocks.

Thereâ€™s no substitute for good software design. Code is not yet abstracted away.

LLMs can become so good in the future that code becomes an implementation detail that we almost never look at, but weâ€™re not there yet.\
Â 

## Reflections on working on a vibe-coded project

I helped a friend solve some obscure edge cases in what you would call a vibe-coded codebase. It was a project created mostly with AI with the aim of solving a specific business problem. The directions that were given to the AI were focused on product features instead of code-level details.

The result was very good. It was a great-functioning proof of concept.

But it wasnâ€™t built with extensibility in mind. So when the team wanted to take it beyond the prototype level, they started experiencing problems. The LLM was no longer capable of adding new functionality without breaking something else and sometimes its changes werenâ€™t working at all. The AI was only given instructions about what to build, not how to structure the code, and how to make sure that certain parts can be changed without affecting others.

I made an experiment and decided to attempt to fix the problems entirely with Cursor without writing the code myself.

ğŸ”´ Describing the bug the users are facing **didnâ€™t work**. It rarely gave good suggestions at all.\
ğŸŸ¡ Describing the bug in a technical way **gave better results**. However it often started refactoring whole files while there was a simpler solution available. It needed more guidance.\
ğŸŸ¢ Telling it what technical change you want to make **gave the best result**. I basically designed the solution in my head, described it to the LLM and it implemented it, taking care of edge cases.

Typing the code becomes a solved problem with every passing day, designing solutions however, is still hard. This is the difference between creating a data pipeline in a single file and having an extensible solution that you can use an LLM to enrich and extend.

*Well, that's about it. Let's go create something!*


