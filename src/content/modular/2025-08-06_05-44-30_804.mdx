---
layout: ../../layouts/BlogLayout.astro
title: New in Modular Platform 25.5： Large Scale Batch Inference, standalone Mojo packages, open source MAX Graph API, and seamless MAX <> PyTorch integration
description: New in Modular Platform 25.5： Large Scale Batch Inference, standalone Mojo packages, open source MAX Graph API, and seamless MAX <> PyTorch integration
date: 星期三 05 凌晨 八月 6o 2025
author: modular
origin_url: javascript:;
origin_site: javascript:;
translated: true
avatar: /media-source/modular-ico.png
email_recorder: hello@modular.com
---

import { Detail } from '@/components/Detail.tsx';
import { Reference } from '@/components/Reference.tsx';

<Reference client:only="react" title="New in Modular Platform 25.5： Large Scale Batch Inference, standalone Mojo packages, open source MAX Graph API, and seamless MAX <> PyTorch integration" url="javascript:;" />

<Detail client:only="react">
	New in Modular Platform 25.5: Large Scale Batch Inference, standalone Mojo packages, open source MAX Graph API, and seamless MAX &lt;> PyTorch integration          @media only screen and (max-width:639px)&lcub;img.stretch-on-mobile,.hs\_rss\_email\_entries\_table img,.hs-stretch-cta .hs-cta-img&lcub;height:auto !important;width:100% !important} .display\_block\_on\_small\_screens&lcub;display:block}.hs\_padded&lcub;padding-left:20px !important;padding-right:20px !important} .hs-hm,table.hs-hm&lcub;display:none}.hs-hd&lcub;display:block !important}table.hs-hd&lcub;display:table !important} }@media only screen and (max-width:639px)&lcub;.hse-border-m&lcub;border-left:1px solid #cbd6e2 !important;border-right:1px solid #cbd6e2 !important;box-sizing:border-box} .hse-border-bottom-m&lcub;border-bottom:1px solid #cbd6e2 !important}.hse-border-top-m&lcub;border-top:1px solid #cbd6e2 !important} .hse-border-top-hm&lcub;border-top:none !important}.hse-border-bottom-hm&lcub;border-bottom:none !important} }.moz-text-html .hse-column-container&lcub;max-width:600px !important;width:600px !important} .moz-text-html .hse-column&lcub;display:table-cell;vertical-align:top}.moz-text-html .hse-section .hse-size-6&lcub;max-width:300px !important;width:300px !important} .moz-text-html .hse-section .hse-size-12&lcub;max-width:600px !important;width:600px !important} @media only screen and (min-width:640px)&lcub;.hse-column-container&lcub;max-width:600px !important;width:600px !important} .hse-column&lcub;display:table-cell;vertical-align:top}.hse-section .hse-size-6&lcub;max-width:300px !important;width:300px !important} .hse-section .hse-size-12&lcub;max-width:600px !important;width:600px !important} }@media only screen and (max-width:639px)&lcub;.hse-body-wrapper-td&lcub;padding-top:20px !important} #section-0 .hse-column-container&lcub;padding-top:10px !important;padding-bottom:10px !important;background-color:transparent !important} #section-0 .hse-column-container&lcub;background-color:transparent !important} }@media only screen and (max-width:639px)&lcub; #section-1 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-1 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-2 .hse-column-container&lcub;padding-top:10px !important;padding-bottom:0px !important} #section-2 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-3 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-3 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-4 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-4 .hse-column-container&lcub;background-color:#fff !important} }@media screen and (max-width:639px)&lcub;.social-network-cell&lcub;display:inline-block} }@media only screen and (max-width:639px)&lcub; #section-5 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-5 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-6 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-6 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub;.hse-body-wrapper-td&lcub;padding-bottom:20px !important} #section-7 .hse-column-container&lcub;padding-top:30px !important;padding-bottom:0px !important;background-color:transparent !important} #section-7 .hse-column-container&lcub;background-color:transparent !important} }#hs\_body #hs\_cos\_wrapper\_main a\[x-apple-data-detectors\]&lcub;color:inherit !important;text-decoration:none !important;font-size:inherit !important;font-family:inherit !important;font-weight:inherit !important;line-height:inherit !important} a&lcub;text-decoration:underline}p&lcub;margin:0}body&lcub;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased;moz-osx-font-smoothing:grayscale} table&lcub;border-spacing:0;mso-table-lspace:0;mso-table-rspace:0}table,td&lcub;border-collapse:collapse} img&lcub;-ms-interpolation-mode:bicubic}p,a,li,td,blockquote&lcub;mso-line-height-rule:exactly}

Introducing Large Scale Batch Inference: a highly asynchronous, at-scale batch API built on open standards and powered by Mammoth. We're launching this new capability through our partner SF Compute, enabling high-volume AI performance with a fast, accurate, and efficient platform that seamlessly scales workloads across any hardware.

[![Modular](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/Group%201%20(5).png?width=1120&upscale=true&name=Group%201%20(5).png)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZ03m2nnW6N1vHY6lZ3kwN7N4DBW8r87jW2r3HXT5mN2STW1XLlFD2LDGWdN7m3Mw8KLYs8W1K_0FZ1PYSlFV_s7DS40ssFtW7SDzb82kF82vW4GCQ1c41PnbqW6W-_4648Xf17W2MX24V8JlgKTN1v1HBjgxJFwN36_LCZS5sHlW3Sdk7Q7J_-YzN466Fvn_qf37W4JMKJ28c30h3W8HPDxV73gXFJW17ySZ868YMjNW960XsV5-RpDmW75pd4y57PtyTW3Zl5Z81kNWM0W8ykpY06CDCfSW86SQGl5PlJ9Ff4z9LGP04)

## Modular Platform 25.5: Introducing Large Scale Batch Inference

[![25_5 1](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/25_5%201.png?width=1120&upscale=true&name=25_5%201.png)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZC3qn9qW7Y8-PT6lZ3nTW5BZLMD4gmHCdW184jmV5DWPPNW2xsV177CjPb8W2Gb-gw6Lvtf-W8lZXRh4K1q5PMZ6n7DdRDnWW61KgtY2BqMkHW6QxFzF7dSPxcW3ZL30k3dk04YW98-V9_5vm34FW8ZWRVd1cvRJ1W4gB58y8Hq72GW8BMWF53dZgJ1W1gH7PJ3l1rDMW5jd4fy9cmJRwW7M6-lv3g0gTSW7FZV524Q-RvfW9gv8rZ7XslqHW6McvQW1RTlVqW3nvH5m7X6Cw4W8LFSNV7xKmfhW3hglDM15yK2yW4pzd2x7-LsHxN77R54MhprmCW4M9KCw2p0DJjW8xXgLD1sgPSpf1j9BST04)

Modular Platform 25.5 is built for developers who need performance at scale. The standout feature is Large Scale Batch Inference, a high-throughput, OpenAI-compatible API built on open standards and powered by Mammoth, our intelligent orchestration layer. It enables seamless scaling across both NVIDIA and AMD hardware and is already in production through [our partner SF Compute](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3qn9qW7lCdLW6lZ3pBN3w0rTnZKQPnW8ngdjD57mQGwW81bYB567hyvNW19nQVX6bLWjCW5vL0N-1-z7nRW150XgR8fzqRlW1WJSCm4s2ss4VXmHMN2QDNprW7JZnP33M3vVgW43sqQq5pHgQ7W78QN1N187_bfW1gb1lC1K-dvvW4tYHhw52dqvDN8LNZXc3KhHQW3K6jpD2CSYy-W67yWPP1X04t-W5d6v0M78PpryW8vJdCD3mN21GW79Qsmn8pBGsPW7xpqHf42H7bFW2SZrw23vN0wzN6ML2ml3chbWW6xvDSs7vkp1RVm0tRk8GYQHLf90Dlpl04). [You can try it today](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3ntN42wGCTR3081M-jX7QvW6wxN4lZ3prZfbJ8W2y8sks342PYGN8QbZSYD27X5W1BYhv9759SSrN11B_6QfDTrDW3vFLbB8b_k5YW3RNLmx7kZ58WVsq6sM4VgG7bW7WYMJq15y6fLW3RCpy53_KylHW7b73Vg5-YJBwN1DGSwmMwCLZW2R9V7B63FmmWW95Tdqr3BVGNJW2F0DRw7T5s89W4XTLBX2-TcttW4FWsGM8msqtpVnN-k25fFd7PVll-Ls5348_lW8Hls5p7-15jBW4QfBJz5sSBBfW8HrYrF5DsNbzf8SvZJ604) with over 20 open models.

We’ve also made major improvements across the stack:

*   **Standalone Mojo Conda packages** make Mojo development and deployment easier than ever.
*   **The MAX Graph API is now fully open source, including supporting code and unit tests.** You can build portable, GPU-accelerated graphs directly in Python.
*   **MAX graphs can now be seamlessly integrated into PyTorch workflows.** Use the new @graph\_op decorator to turn any MAX graph into a PyTorch operator.

This release also includes performance boosts for MAX, expanded Mojo language features, and dramatically smaller serving packages for NVIDIA GPUs.

[**Read the full blog post**](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZC3qn9qW7Y8-PT6lZ3kvVx5rjw8m8zRhVk1b0x1R6XRFW60G4ZP5Q_sFkW3HsMK-6tTH1nW6sMDdt47bBc2VTs7p61DypdKW3XQKdw8GFqW1W6F3dWw1w14hpW8G19X08HkrXnW2q62DV62QjVJW7GtX_D4JcSHYW4VJghg5GMDDLW784yCf85Nm7QVCl_sx7ZgjjxW4wW8-D68Fn9VW5bpXKP5Vpz92W64VB2v7ZhGT1W8JlwPl5rHCpfVQWSYq4yf7vBW2BFxq87cnLcCW5NWFr_69h_GvW1sD2K-37_C1ZW4jzjr16CtxBhW1YZKgX4_QpNwW96ZsC15kSKF9W49MV452VV1J1f2gTTs804)

Livestream: Introducing Modular Platform 25.5

[![Mojo_Mic](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/Mojo_Mic.jpg?width=520&upscale=true&name=Mojo_Mic.jpg)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3q2VSmLR72pyRx_W8K-3tD6_-W3PW7hqDYT8HB8vLW5zj5Rm2X8bXvW3pv-5K3npHddW8Q1wx02LVr5-W8G-Fgc9hxZF7W6Y5D-P6r8MHVW4bMJm03cZpDcW3NmgQ24KSzS9W4zC-mG6m3WV5W7QNd8Z2Q7vZTW3RnL6Q73wWdQW6fVnZk188gYYV1RxHY82PsTpW24NLgj7LMyWXW7L_qxK1LbrY2W2fwTyN5Ph0X-W7nkK0T3mXrd9W3LHfSt3FSRHyW59-V621rR_msW6ZX6Tp5HLxRMW8mgqVN6hPVNcW17yX428Gk_yvf5lKqNY04)

Get an inside look at what’s new in Modular Platform 25.5. The team will walk through the latest updates to MAX and Mojo, our enhanced PyTorch integration, and Large Scale Batch Inference powered by Mammoth, followed by a live Q&A.

[**RSVP to join virtually**](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3kFF2SpQMq3R1vW31gkGx59x93YW7ys9g98n036hN1cQX13pv_9_W7Pz5Bn6PkhlQW5VdzSt2MG86bW2dRgXb8XqgH2W1FtQLS3jR1hqW46vBTl5zv-N4W3sPp024q1pNyW5wggn076ylS1W5wC2GS44xrHCW3pyvsX8hv7TVW7ybyFD8hZN3_W73kcZJ2jKgLwN85DBrB-FHlLW2JXtps1YjK0BVMzThg8zMydTW2Cw0cZ4J3-qPVd4FR99g3vT7N4xwJdps5wp6N35ky6rnRtQfN6Fzy5l3hvRjW941Yr61cCT2pf6kVxX204)

## Modular Community Meetup

[![Mammoth_Mojo_MAX](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/Mammoth_Mojo_MAX.jpeg?width=520&upscale=true&name=Mammoth_Mojo_MAX.jpeg)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3p3W5pY53K2bMcsQW75ntkC7nFlV-W5zNtr94BTqrgW4NJFmw4Cv8XCW3VgLyv4H4P8VW4vrrX737snkFV-VQGm8tpKnlVffXpY14jmc1V-C12r7PdsTjW1DRZDZ3drpY3W1Fk3Tt68j39JN8W1KvJYwh3YW1cZFlJ80qz-SW2b2Vv-59SYBTW3ndwMR7S0tTrN1FJ7mClLMYKW6rmLxm3QDXcpW947VzT4DTMBBW6LRDr_66kKdtW1V6cm060zJ9RN1X79RdB-Y8xN4Z2CbjHQcg-N62nc7wb0PT6W2kR1Ds6vqk46f8VHkrY04)

​Join us at the Modular office in Los Altos, CA for our next community meetup! Hear from the Modular team as we share updates and insights on building the future of AI infra. Can't make it in person? Select the virtual attendance option and we'll send you a link to join.

[**Save your spot**](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3q2W4lc7QQ8_-ss8N6VkBQlFpp3-W4kVyM17KQcRQW5w7gbw8D_YH5W52sHlP61fWntW7M62n13Tf-4gW56J3Sc5YdXvYVldsJH5R6NB0W5YkRSN11YVDHW2ckS_k56J3SsW5W0SvY7hR2LXW7ZV8NY20BvxJVzV8Ds85Xt7nVy2vk83RGVY0W5VQmyJ57XLcxN3wPBSmkTX5cW7cmTXk15248DW19Stgr5X8RnvW3VJVD-7qCB48W2jVYG15H9QG-VwhfpP2hJ1B5W8bkfZn9hJpN2W5J-kTX40SC7sW7c-3KH3ckkmyf5pKjrK04)


</Detail>

New in Modular Platform 25.5: Large Scale Batch Inference, standalone Mojo packages, open source MAX Graph API, and seamless MAX &lt;> PyTorch integration          @media only screen and (max-width:639px)&lcub;img.stretch-on-mobile,.hs\_rss\_email\_entries\_table img,.hs-stretch-cta .hs-cta-img&lcub;height:auto !important;width:100% !important} .display\_block\_on\_small\_screens&lcub;display:block}.hs\_padded&lcub;padding-left:20px !important;padding-right:20px !important} .hs-hm,table.hs-hm&lcub;display:none}.hs-hd&lcub;display:block !important}table.hs-hd&lcub;display:table !important} }@media only screen and (max-width:639px)&lcub;.hse-border-m&lcub;border-left:1px solid #cbd6e2 !important;border-right:1px solid #cbd6e2 !important;box-sizing:border-box} .hse-border-bottom-m&lcub;border-bottom:1px solid #cbd6e2 !important}.hse-border-top-m&lcub;border-top:1px solid #cbd6e2 !important} .hse-border-top-hm&lcub;border-top:none !important}.hse-border-bottom-hm&lcub;border-bottom:none !important} }.moz-text-html .hse-column-container&lcub;max-width:600px !important;width:600px !important} .moz-text-html .hse-column&lcub;display:table-cell;vertical-align:top}.moz-text-html .hse-section .hse-size-6&lcub;max-width:300px !important;width:300px !important} .moz-text-html .hse-section .hse-size-12&lcub;max-width:600px !important;width:600px !important} @media only screen and (min-width:640px)&lcub;.hse-column-container&lcub;max-width:600px !important;width:600px !important} .hse-column&lcub;display:table-cell;vertical-align:top}.hse-section .hse-size-6&lcub;max-width:300px !important;width:300px !important} .hse-section .hse-size-12&lcub;max-width:600px !important;width:600px !important} }@media only screen and (max-width:639px)&lcub;.hse-body-wrapper-td&lcub;padding-top:20px !important} #section-0 .hse-column-container&lcub;padding-top:10px !important;padding-bottom:10px !important;background-color:transparent !important} #section-0 .hse-column-container&lcub;background-color:transparent !important} }@media only screen and (max-width:639px)&lcub; #section-1 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-1 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-2 .hse-column-container&lcub;padding-top:10px !important;padding-bottom:0px !important} #section-2 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-3 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-3 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-4 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-4 .hse-column-container&lcub;background-color:#fff !important} }@media screen and (max-width:639px)&lcub;.social-network-cell&lcub;display:inline-block} }@media only screen and (max-width:639px)&lcub; #section-5 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-5 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub; #section-6 .hse-column-container&lcub;padding-top:0px !important;padding-bottom:0px !important} #section-6 .hse-column-container&lcub;background-color:#fff !important} }@media only screen and (max-width:639px)&lcub;.hse-body-wrapper-td&lcub;padding-bottom:20px !important} #section-7 .hse-column-container&lcub;padding-top:30px !important;padding-bottom:0px !important;background-color:transparent !important} #section-7 .hse-column-container&lcub;background-color:transparent !important} }#hs\_body #hs\_cos\_wrapper\_main a\[x-apple-data-detectors]&lcub;color:inherit !important;text-decoration:none !important;font-size:inherit !important;font-family:inherit !important;font-weight:inherit !important;line-height:inherit !important} a&lcub;text-decoration:underline}p&lcub;margin:0}body&lcub;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased;moz-osx-font-smoothing:grayscale} table&lcub;border-spacing:0;mso-table-lspace:0;mso-table-rspace:0}table,td&lcub;border-collapse:collapse} img&lcub;-ms-interpolation-mode:bicubic}p,a,li,td,blockquote&lcub;mso-line-height-rule:exactly}

Introducing Large Scale Batch Inference: a highly asynchronous, at-scale batch API built on open standards and powered by Mammoth. We're launching this new capability through our partner SF Compute, enabling high-volume AI performance with a fast, accurate, and efficient platform that seamlessly scales workloads across any hardware.

[![Modular](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/Group%201%20\(5\).png?width=1120\&upscale=true\&name=Group%201%20\(5\).png)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZ03m2nnW6N1vHY6lZ3kwN7N4DBW8r87jW2r3HXT5mN2STW1XLlFD2LDGWdN7m3Mw8KLYs8W1K_0FZ1PYSlFV_s7DS40ssFtW7SDzb82kF82vW4GCQ1c41PnbqW6W-_4648Xf17W2MX24V8JlgKTN1v1HBjgxJFwN36_LCZS5sHlW3Sdk7Q7J_-YzN466Fvn_qf37W4JMKJ28c30h3W8HPDxV73gXFJW17ySZ868YMjNW960XsV5-RpDmW75pd4y57PtyTW3Zl5Z81kNWM0W8ykpY06CDCfSW86SQGl5PlJ9Ff4z9LGP04)

## Modular Platform 25.5: Introducing Large Scale Batch Inference

[![25\_5 1](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/25_5%201.png?width=1120\&upscale=true\&name=25_5%201.png)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZC3qn9qW7Y8-PT6lZ3nTW5BZLMD4gmHCdW184jmV5DWPPNW2xsV177CjPb8W2Gb-gw6Lvtf-W8lZXRh4K1q5PMZ6n7DdRDnWW61KgtY2BqMkHW6QxFzF7dSPxcW3ZL30k3dk04YW98-V9_5vm34FW8ZWRVd1cvRJ1W4gB58y8Hq72GW8BMWF53dZgJ1W1gH7PJ3l1rDMW5jd4fy9cmJRwW7M6-lv3g0gTSW7FZV524Q-RvfW9gv8rZ7XslqHW6McvQW1RTlVqW3nvH5m7X6Cw4W8LFSNV7xKmfhW3hglDM15yK2yW4pzd2x7-LsHxN77R54MhprmCW4M9KCw2p0DJjW8xXgLD1sgPSpf1j9BST04)

Modular Platform 25.5 is built for developers who need performance at scale. The standout feature is Large Scale Batch Inference, a high-throughput, OpenAI-compatible API built on open standards and powered by Mammoth, our intelligent orchestration layer. It enables seamless scaling across both NVIDIA and AMD hardware and is already in production through [our partner SF Compute](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3qn9qW7lCdLW6lZ3pBN3w0rTnZKQPnW8ngdjD57mQGwW81bYB567hyvNW19nQVX6bLWjCW5vL0N-1-z7nRW150XgR8fzqRlW1WJSCm4s2ss4VXmHMN2QDNprW7JZnP33M3vVgW43sqQq5pHgQ7W78QN1N187_bfW1gb1lC1K-dvvW4tYHhw52dqvDN8LNZXc3KhHQW3K6jpD2CSYy-W67yWPP1X04t-W5d6v0M78PpryW8vJdCD3mN21GW79Qsmn8pBGsPW7xpqHf42H7bFW2SZrw23vN0wzN6ML2ml3chbWW6xvDSs7vkp1RVm0tRk8GYQHLf90Dlpl04). [You can try it today](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3ntN42wGCTR3081M-jX7QvW6wxN4lZ3prZfbJ8W2y8sks342PYGN8QbZSYD27X5W1BYhv9759SSrN11B_6QfDTrDW3vFLbB8b_k5YW3RNLmx7kZ58WVsq6sM4VgG7bW7WYMJq15y6fLW3RCpy53_KylHW7b73Vg5-YJBwN1DGSwmMwCLZW2R9V7B63FmmWW95Tdqr3BVGNJW2F0DRw7T5s89W4XTLBX2-TcttW4FWsGM8msqtpVnN-k25fFd7PVll-Ls5348_lW8Hls5p7-15jBW4QfBJz5sSBBfW8HrYrF5DsNbzf8SvZJ604) with over 20 open models.

We’ve also made major improvements across the stack:

* **Standalone Mojo Conda packages** make Mojo development and deployment easier than ever.
* **The MAX Graph API is now fully open source, including supporting code and unit tests.** You can build portable, GPU-accelerated graphs directly in Python.
* **MAX graphs can now be seamlessly integrated into PyTorch workflows.** Use the new @graph\_op decorator to turn any MAX graph into a PyTorch operator.

This release also includes performance boosts for MAX, expanded Mojo language features, and dramatically smaller serving packages for NVIDIA GPUs.

[**Read the full blog post**](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZC3qn9qW7Y8-PT6lZ3kvVx5rjw8m8zRhVk1b0x1R6XRFW60G4ZP5Q_sFkW3HsMK-6tTH1nW6sMDdt47bBc2VTs7p61DypdKW3XQKdw8GFqW1W6F3dWw1w14hpW8G19X08HkrXnW2q62DV62QjVJW7GtX_D4JcSHYW4VJghg5GMDDLW784yCf85Nm7QVCl_sx7ZgjjxW4wW8-D68Fn9VW5bpXKP5Vpz92W64VB2v7ZhGT1W8JlwPl5rHCpfVQWSYq4yf7vBW2BFxq87cnLcCW5NWFr_69h_GvW1sD2K-37_C1ZW4jzjr16CtxBhW1YZKgX4_QpNwW96ZsC15kSKF9W49MV452VV1J1f2gTTs804)

Livestream: Introducing Modular Platform 25.5

[![Mojo\_Mic](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/Mojo_Mic.jpg?width=520\&upscale=true\&name=Mojo_Mic.jpg)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3q2VSmLR72pyRx_W8K-3tD6_-W3PW7hqDYT8HB8vLW5zj5Rm2X8bXvW3pv-5K3npHddW8Q1wx02LVr5-W8G-Fgc9hxZF7W6Y5D-P6r8MHVW4bMJm03cZpDcW3NmgQ24KSzS9W4zC-mG6m3WV5W7QNd8Z2Q7vZTW3RnL6Q73wWdQW6fVnZk188gYYV1RxHY82PsTpW24NLgj7LMyWXW7L_qxK1LbrY2W2fwTyN5Ph0X-W7nkK0T3mXrd9W3LHfSt3FSRHyW59-V621rR_msW6ZX6Tp5HLxRMW8mgqVN6hPVNcW17yX428Gk_yvf5lKqNY04)

Get an inside look at what’s new in Modular Platform 25.5. The team will walk through the latest updates to MAX and Mojo, our enhanced PyTorch integration, and Large Scale Batch Inference powered by Mammoth, followed by a live Q\&A.

[**RSVP to join virtually**](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3kFF2SpQMq3R1vW31gkGx59x93YW7ys9g98n036hN1cQX13pv_9_W7Pz5Bn6PkhlQW5VdzSt2MG86bW2dRgXb8XqgH2W1FtQLS3jR1hqW46vBTl5zv-N4W3sPp024q1pNyW5wggn076ylS1W5wC2GS44xrHCW3pyvsX8hv7TVW7ybyFD8hZN3_W73kcZJ2jKgLwN85DBrB-FHlLW2JXtps1YjK0BVMzThg8zMydTW2Cw0cZ4J3-qPVd4FR99g3vT7N4xwJdps5wp6N35ky6rnRtQfN6Fzy5l3hvRjW941Yr61cCT2pf6kVxX204)

## Modular Community Meetup

[![Mammoth\_Mojo\_MAX](https://hs-24141518.f.hubspotemail.net/hub/24141518/hubfs/Mammoth_Mojo_MAX.jpeg?width=520\&upscale=true\&name=Mammoth_Mojo_MAX.jpeg)](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3p3W5pY53K2bMcsQW75ntkC7nFlV-W5zNtr94BTqrgW4NJFmw4Cv8XCW3VgLyv4H4P8VW4vrrX737snkFV-VQGm8tpKnlVffXpY14jmc1V-C12r7PdsTjW1DRZDZ3drpY3W1Fk3Tt68j39JN8W1KvJYwh3YW1cZFlJ80qz-SW2b2Vv-59SYBTW3ndwMR7S0tTrN1FJ7mClLMYKW6rmLxm3QDXcpW947VzT4DTMBBW6LRDr_66kKdtW1V6cm060zJ9RN1X79RdB-Y8xN4Z2CbjHQcg-N62nc7wb0PT6W2kR1Ds6vqk46f8VHkrY04)

​Join us at the Modular office in Los Altos, CA for our next community meetup! Hear from the Modular team as we share updates and insights on building the future of AI infra. Can't make it in person? Select the virtual attendance option and we'll send you a link to join.

[**Save your spot**](https://d2Sj-804.na1.hubspotlinks.com/Ctc/DP+113/d2Sj-804/MWRvWkxkFpYN4SRjbP2q-KsW1TDTHt5zVshxN6R-BZj3m2nnW7lCdLW6lZ3q2W4lc7QQ8_-ss8N6VkBQlFpp3-W4kVyM17KQcRQW5w7gbw8D_YH5W52sHlP61fWntW7M62n13Tf-4gW56J3Sc5YdXvYVldsJH5R6NB0W5YkRSN11YVDHW2ckS_k56J3SsW5W0SvY7hR2LXW7ZV8NY20BvxJVzV8Ds85Xt7nVy2vk83RGVY0W5VQmyJ57XLcxN3wPBSmkTX5cW7cmTXk15248DW19Stgr5X8RnvW3VJVD-7qCB48W2jVYG15H9QG-VwhfpP2hJ1B5W8bkfZn9hJpN2W5J-kTX40SC7sW7c-3KH3ckkmyf5pKjrK04)


